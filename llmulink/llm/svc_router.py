import re
import uuid
import random
import asyncio
import logging

import asab
import yaml
import jinja2

from .datamodel import Conversation, UserMessage, Exchange, FunctionCall, FunctionCallTool

from .provider.v1response import LLMChatProviderV1Response
from .provider.v1messages import LLMChatProviderV1Messages
from .provider.v1chatcompletition import LLMChatProviderV1ChatCompletition

#

L = logging.getLogger(__name__)

#

class LLMRouterService(asab.Service):


	def __init__(self, app, service_name="LLMRouterService"):
		super().__init__(app, service_name)

		self.LibraryService = app.LibraryService

		self.Providers = []
		self.Conversations = dict[str, Conversation]()

		self.load_providers()


	def load_providers(self):
		for section in asab.Config.sections():
			if not section.startswith("provider:"):
				continue

			ptype = asab.Config[section].get('type')
			match ptype:
				case 'LLMChatProviderV1Response':
					self.Providers.append(LLMChatProviderV1Response(self, **asab.Config[section]))
				case 'LLMChatProviderV1Messages':
					self.Providers.append(LLMChatProviderV1Messages(self, **asab.Config[section]))
				case 'LLMChatProviderV1ChatCompletition':
					self.Providers.append(LLMChatProviderV1ChatCompletition(self, **asab.Config[section]))
				case _:
					L.warning("Unknown provider type, skipping", struct_data={"type": ptype})


	async def create_conversation(self):
		while True:
			conversation_id = 'conversation-' + uuid.uuid4().hex
			if conversation_id in self.Conversations:
				continue
			break

		L.log(asab.LOG_NOTICE, "New conversation created", struct_data={"conversation_id": conversation_id})

		async with self.LibraryService.open("/AI/Prompts/default.yaml") as item_io:
			promt_decl = yaml.safe_load(item_io.read().decode("utf-8"))

		conversation = Conversation(
			conversation_id=conversation_id,
			instructions=promt_decl["instructions"],
			tools=self.App.ToolService.get_tools()
		)
		self.Conversations[conversation.conversation_id] = conversation
		return conversation


	async def stop_conversation(self, conversation: Conversation) -> None:
		for task in conversation.tasks:
			conversation.chat_requested = False
			task.cancel()
		L.log(asab.LOG_NOTICE, "Conversation stopped", struct_data={"conversation_id": conversation.conversation_id})


	def restart_conversation(self, conversation: Conversation, key: str) -> None:
		for i in range(len(conversation.exchanges)):
			if conversation.exchanges[i].items[0].key == key:
				del conversation.exchanges[i:]
				return
		L.warning("Conversation restart failed", struct_data={"conversation_id": conversation.conversation_id, "key": key})
			

	async def update_instructions(self, conversation: Conversation, item: str, params: dict) -> None:
		assert item.startswith("/AI/Prompts/"), "Item must be a prompt in the AI/Prompts directory"
		
		async with self.LibraryService.open(item) as item_io:
			promt_decl = yaml.safe_load(item_io.read().decode("utf-8"))

		instructions = promt_decl["instructions"]
		conversation.instructions = jinja2.Template(instructions).render(params)


	async def get_conversation(self, conversation_id, create=False):
		conversation = self.Conversations.get(conversation_id)
		if conversation is None and create:
			conversation = await self.create_conversation(conversation_id)
		return conversation


	async def create_exchange(self, conversation: Conversation, item: UserMessage) -> None:
		new_exchange = Exchange()
		conversation.exchanges.append(new_exchange)

		new_exchange.items.append(item)
		await self.send_update(conversation, {
			"type": "item.appended",
			"item": item.to_dict(),
		})

		await self.schedule_task(conversation, new_exchange, self.task_chat_request)


	async def schedule_task(self, conversation: Conversation, exchange: Exchange, task, *args, **kwargs) -> None:
		t = asyncio.create_task(
			task(conversation, exchange, *args, **kwargs),
			name=f"conversation-{conversation.conversation_id}-task"
		)

		def on_task_done(task):
			conversation.tasks.remove(task)

			if len(conversation.tasks) == 0 and conversation.chat_requested:
				# Initialize a new exchange with LLM
				new_exchange = Exchange()
				conversation.exchanges.append(new_exchange)
				conversation.chat_requested = False

				t = asyncio.create_task(
					self.task_chat_request(conversation, new_exchange),
					name=f"conversation-{conversation.conversation_id}-task"
				)
				t.add_done_callback(on_task_done)
				conversation.tasks.append(t)

			asyncio.create_task(self.send_update_tasks(conversation))

		t.add_done_callback(on_task_done)

		conversation.tasks.append(t)
		await self.send_update_tasks(conversation)
		

	async def send_update_tasks(self, conversation: Conversation) -> None:
		await self.send_update(
			conversation,
			{
				"type": "tasks.updated",
				"count": len(conversation.tasks) + (1 if conversation.chat_requested else 0),
			}
		)


	async def task_chat_request(self, conversation: Conversation, exchange: Exchange) -> None:
		model = conversation.get_model()
		assert model is not None, "Model is not set"

		# Find and select a provider for the model
		providers = [provider for provider in self.Providers if model in set(model['id'] for model in provider.Models)]
		assert len(providers) > 0, "No provider found for model"
		provider = random.choice(providers)

		async def print_waiting():
			while True:
				await asyncio.sleep(1)
				# TODO: Indicate waiting for a model in the UI
				print("Waiting for a model ...")

		waiting_task = asyncio.create_task(print_waiting())
		try:
			async with provider.Semaphore:
				waiting_task.cancel()
				await provider.chat_request(conversation, exchange)
		finally:
			waiting_task.cancel()
			

	async def get_models(self):
		models = []

		async def collect_models(models, provider):
			try:
				pmodels = await provider.get_models()
			except Exception as e:
				L.exception("Error collecting models", struct_data={"provider": provider.__class__.__name__})
				return

			if pmodels is not None:
				models.extend(pmodels)

		async with asyncio.TaskGroup() as tg:
			for provider in self.Providers:
				tg.create_task(collect_models(models, provider))

		return models


	async def send_update(self, conversation: Conversation, event: dict):
		async with asyncio.TaskGroup() as tg:
			for monitor in conversation.monitors:
				tg.create_task(monitor(event))


	async def send_full_update(self, conversation: Conversation, monitor):
		items = []
		full_update = {
			"type": "update.full",
			"conversation_id": conversation.conversation_id,
			"created_at": conversation.created_at.isoformat(),
			"items": items,
		}

		for exchange in conversation.exchanges:
			for item in exchange.items:
				match item.__class__:
					case UserMessage:
						items.append(item.to_dict())

		try:
			await monitor(full_update)
		except Exception:
			L.exception("Error sending full update to monitors", struct_data={"conversation_id": conversation.conversation_id})


	async def create_function_call(self, conversation: Conversation, function_call: FunctionCall):
		await self.schedule_task(conversation, function_call, self.task_function_call)
		

	async def task_function_call(self, conversation: Conversation, function_call: FunctionCall) -> None:
		L.log(asab.LOG_NOTICE, "Calling function ...", struct_data={"name": function_call.name})

		function_call.status = 'executing'
		await self.send_update(conversation, {
			"type": "item.updated",
			"item": function_call.to_dict(),
		})

		try:
			async for _ in self.App.ToolService.execute(function_call):
				await self.send_update(conversation, {
					"type": "item.updated",
					"item": function_call.to_dict(),
				})

		except Exception as e:
			L.exception("Error in function call", struct_data={"name": function_call.name})
			function_call.content = "Generic exception occurred. Try again."
			function_call.error = True

		finally:
			function_call.status = 'finished'
			await self.send_update(conversation, {
				"type": "item.updated",
				"item": function_call.to_dict(),
			})

			# Flag the conversation that is chat requested
			conversation.chat_requested = True


def normalize_text(text: str) -> str:
	'''
	Normalize the text to be a single line of text.
	All newlines, tabs, and multiple spaces are replaced with a single space.
	Leading and trailing spaces are removed.
	'''
	return re.sub(r'\s+', ' ', text.strip())
